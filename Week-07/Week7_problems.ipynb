{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4660a734",
   "metadata": {
    "id": "4660a734"
   },
   "source": [
    "# COMP0189: Applied Artificial Intelligence\n",
    "# Week 7 (Dimensionality reduction and matrix decomposition)\n",
    "\n",
    "### üéØ Objectives\n",
    "1. To understand the differences in applying various dimensionality reduction techniques like Principal Component Analysis (PCA), Independent Component Analysis (ICA), Non-negative Matrix Factorization (NMF) to extract latent features from an image dataset\n",
    "2. To apply cross decomposition methods like Canonical Correlation Analysis (CCA) and PArtial Least Squares (PLS) to find the fundamental relations between two matrices (X and Y) that represent different views of the same data\n",
    "\n",
    "### Acknowledgements\n",
    "- https://scikit-learn.org/stable/\n",
    "- https://scikit-learn.org/stable/auto_examples/applications/plot_face_recognition.html#sphx-glr-auto-examples-applications-plot-face-recognition-py\n",
    "- https://oasis-brains.org\n",
    "- https://cca-zoo.readthedocs.io/en/latest/preface.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c1bdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn==1.5.2 cca-zoo matplotlib seaborn pandas scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5Y4jLgPv-AKD",
   "metadata": {
    "id": "5Y4jLgPv-AKD"
   },
   "source": [
    "## üßë‚Äçüíª Part 1. Face recognition through eigenfaces and SVMs\n",
    "\n",
    "This part of the lab will focus on different dimensionality reduction (or matrix decomposition) methods. We will use the [Labelled Faces in the Wild](https://scikit-learn.org/stable/datasets/real_world.html#labeled-faces-in-the-wild-dataset) (LFW) dataset distributed with `scikit-learn` to visualise the results of dimensionality reduction methods and assess their impact on model performance and training time.\n",
    "\n",
    "The dataset provides the faces of several famous people labelled with their name. We will use it to train a model which predicts a person's name given a picture of their face."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C19iCiwDEq_J",
   "metadata": {
    "id": "C19iCiwDEq_J"
   },
   "source": [
    "### üìù Task 1.1 Import Libraries and Load the Labeled Faces in the Wild (LFW) People Dataset (Classification)\n",
    "\n",
    "First, we load in the LFW data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zjL-liTEF02-",
   "metadata": {
    "id": "zjL-liTEF02-"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "X = lfw_people.data\n",
    "y = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "n_classes = target_names.shape[0]\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# Split into a training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UVAm12_2F369",
   "metadata": {
    "id": "UVAm12_2F369"
   },
   "source": [
    "### üìù Task 1.2 Visualise input data\n",
    "\n",
    "To get an idea of what we're working with, we can visualise the first few faces in the dataset and their associated name. We will later reuse this function to draw the main components from dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8nEuAY45GAVH",
   "metadata": {
    "id": "8nEuAY45GAVH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_gallery(images: npt.NDArray[np.floating], titles: list[str], h: int, w: int, n_row=3, n_col=4):\n",
    "    \"\"\"Helper function to plot a gallery of portraits.\"\"\"\n",
    "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=0.01, right=0.99, top=0.90, hspace=0.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap=\"gray\")\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n",
    "sample_faces = X_train[0:13].reshape((13, h, w))\n",
    "face_titles = [\"%s\" % target_names[t] for t in y_train]\n",
    "plot_gallery(sample_faces, face_titles, h, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NrzAhtU7GEce",
   "metadata": {
    "id": "NrzAhtU7GEce"
   },
   "source": [
    "### üìù Task 1.3 Apply dimensionality reduction methods\n",
    "\n",
    "Now, we can apply different dimensionality reduction methods to the input data. We will compare [Principal Component Analysis](https://scikit-learn.org/stable/modules/decomposition.html#pca) (PCA), [Non-Negative Matrix Factorisation](https://scikit-learn.org/stable/modules/decomposition.html#nmf) (NMF), and [Independent Component Analysis](https://scikit-learn.org/stable/modules/decomposition.html#ica) (ICA).\n",
    "\n",
    "Keep track of how long it took to fit each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AzdWZnNjGMQq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AzdWZnNjGMQq",
    "outputId": "e8a61975-a9bd-4ca9-a053-8f1f0eee9390"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, NMF, FastICA\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7190600c",
   "metadata": {},
   "source": [
    "### üìù Task 1.4 Visualise results\n",
    "\n",
    "We can now visualise the main components learned by each of the dimensionlity reduction methods we just trained. Each of them will have the same dimension as a face, so feel free to reuse the `plot_gallery` function that we previously wrote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15872573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "rpLEetHuGN8P",
   "metadata": {
    "id": "rpLEetHuGN8P"
   },
   "source": [
    "### üìù Task 1.5 Train SVM Classifier using the Components Extraced by the Different Method and Evaluate\n",
    "\n",
    "Finally, we train an SVM classifier to predict a person's name given a picture of their face. How does the classifier's performance change when using no dimensionality reduction compared to the methods trained above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00zhfNx9GS7_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "00zhfNx9GS7_",
    "outputId": "508f8ee7-f2be-494d-f3ae-1ceb7f7cb623"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.svm import SVC\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YbNjxIvkG1oV",
   "metadata": {
    "id": "YbNjxIvkG1oV"
   },
   "source": [
    "### üó£ Discuss:\n",
    "- What are the differences in how PCA, NMF, and ICA capture features.\n",
    "- How do these differences affect the performance of the SVM classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b93f31",
   "metadata": {
    "id": "71b93f31"
   },
   "source": [
    "## üë©‚Äçüíª Part 2: OASIS dataset: Cross decomposition methods\n",
    "\n",
    "In this part, you will learn how to apply cross decomposition methods such as CCA and PLSSVD to find the fundamental relations (or latent dimensions) between two matrices (X and Y) that represent different views of the same data.\n",
    "\n",
    "We will use the Open Access Series of Imaging Studies (OASIS) dataset, which contains brain Magnetic Resonance Images (MRI) (view 1) and clinical assessments (view 2) of 416 subjects aged 18 to 96. The brain images have been summarized into 116 Regions of Interest (ROIs) using the Automated Anatomical Labeling (AAL) atlas (https://www.gin.cnrs.fr/en/tools/aal/). The clinical data consist of tabular data including gender, age, education and two clinical questionnairs, the mini mental state examination (MMSE) and the clinical dementia rating (CDR). The goal is to explore how these two views are related.\n",
    "\n",
    "It is important to note that there are 2 groups in the OASIS data: healthy subjects, and those with dementia. The `OASIS_labels.csv` file contains the label for each subject."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b50c4f1",
   "metadata": {
    "id": "0b50c4f1"
   },
   "source": [
    "### Import libraries and load data\n",
    "\n",
    "First, we need to import some libraries and load the data from CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49df5926",
   "metadata": {
    "id": "49df5926"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "labels = pd.read_csv(\"./OASIS_labels.csv\")\n",
    "brain_roi = pd.read_csv(\"./OASIS_view1_ROI.csv\")\n",
    "clinical = pd.read_csv(\"./OASIS_view2_clinical.csv\")\n",
    "roi_names = pd.read_csv(\"./AAL_ROI_names.csv\", header=None).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3723db4",
   "metadata": {
    "id": "e3723db4"
   },
   "source": [
    "### Data preprocessing\n",
    "\n",
    "Next, we need to do some preprocessing on the data. We will drop some columns that are not relevant for our analysis, such as subject ID, handness, etc. We will also normalize each view by subtracting its mean and dividing by its standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca62b6c",
   "metadata": {
    "id": "7ca62b6c"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "brain_roi = brain_roi.drop([\"Subject ID\"], axis=1)\n",
    "clinical = clinical.drop([\"Subject ID\"], axis=1)\n",
    "\n",
    "# One-hot encode the \"Gender\" column and drop the first column to avoid multicollinearity\n",
    "clinical = pd.get_dummies(clinical, columns=[\"Gender\"], drop_first=True)\n",
    "\n",
    "# Fill nans with mean values\n",
    "brain_roi = brain_roi.fillna(brain_roi.mean(numeric_only=True))\n",
    "clinical = clinical.fillna(clinical.mean(numeric_only=True))\n",
    "\n",
    "brain_roi.columns = roi_names\n",
    "\n",
    "# Convert labels to numbers before the split\n",
    "label_dict = {\"Demented\": 0, \"Nondemented\": 1}\n",
    "labels[\"Group\"] = labels[\"Group\"].map(label_dict)\n",
    "\n",
    "# Split the data and labels into training and testing sets\n",
    "train_brain_roi, test_brain_roi, train_clinical, test_clinical, train_labels, test_labels = train_test_split(\n",
    "    brain_roi, clinical, labels[\"Group\"], test_size=0.3, random_state=42)\n",
    "\n",
    "# Apply StandardScaler separately to training and testing sets to avoid data leakage\n",
    "scaler_brain = StandardScaler()\n",
    "train_brain_roi = scaler_brain.fit_transform(train_brain_roi)\n",
    "test_brain_roi = scaler_brain.transform(test_brain_roi)\n",
    "\n",
    "scaler_clinical = StandardScaler()\n",
    "train_clinical = scaler_clinical.fit_transform(train_clinical)\n",
    "test_clinical = scaler_clinical.transform(test_clinical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DtQvxa9nLzE3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "DtQvxa9nLzE3",
    "outputId": "19062159-8677-462b-ffa8-797fedd5e5fd"
   },
   "outputs": [],
   "source": [
    "brain_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34304e62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "34304e62",
    "outputId": "d571b11f-6340-4b5c-f807-39d6827577fe"
   },
   "outputs": [],
   "source": [
    "clinical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb964452",
   "metadata": {
    "id": "cb964452"
   },
   "source": [
    "### Cross decomposition methods\n",
    "\n",
    "Now we are ready to apply cross decomposition methods to find the relations between the two views. We will use three methods: CCA, regularised CCA and PLSSVD.\n",
    "\n",
    "CCA finds linear combinations of X and Y that have maximum correlation. It can be seen as a generalization of PCA for two sets of variables.\n",
    "\n",
    "Regularised CCA adds a regularisation term to prevent overfitting on the training set.\n",
    "\n",
    "PLSSVD finds linear combinations of X and Y that have maximum covariance. It can be seen as a generalization of SVD for two sets of variables.\n",
    "\n",
    "For both methods, we need to specify the number of components that we want to extract from each view. This parameter controls the dimensionality of the latent space.\n",
    "\n",
    "We will use n_components=2 for both methods. You can try different values later and see how they affect the results.\n",
    "\n",
    "For further comparison, apply PCA to the brain_roi data with 2 components in order to see if combining the modalities changes the latent space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f5fefc",
   "metadata": {
    "id": "23f5fefc"
   },
   "source": [
    "### Task 2.1 - Apply CCA to the brain and clinical dataset and plot the weights for the two first CCA components (brain and clinical)\n",
    "\n",
    "We will use [`cca-zoo`](https://cca-zoo.readthedocs.io/en/latest/#) to carry out the calculations. It's a library which offers support for many different algorithms, including a regularised version of CCA which is not present in `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b96a9a",
   "metadata": {
    "id": "43b96a9a"
   },
   "outputs": [],
   "source": [
    "from cca_zoo.linear import CCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64968bb0",
   "metadata": {
    "id": "64968bb0"
   },
   "source": [
    "### Task 2.2 -  Plot the CCA latent space for the top 2 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WE0g7dFqNFCQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 670
    },
    "id": "WE0g7dFqNFCQ",
    "outputId": "e9aa33f5-879b-49ff-95e8-3c7686667b6b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad466305",
   "metadata": {},
   "source": [
    "### Task 2.3 - Show the same plots, but obtained by applying regularised CCA to the brain and clinical dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81453e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cca_zoo.linear import rCCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba1c034",
   "metadata": {
    "id": "dba1c034"
   },
   "source": [
    "### Task 2.4 - Show the same plots, but obtained by applying PLSSVD to the brain and clinical dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a54190",
   "metadata": {
    "id": "97a54190"
   },
   "outputs": [],
   "source": [
    "from cca_zoo.linear import PLS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c72a629",
   "metadata": {
    "id": "3c72a629"
   },
   "source": [
    "### Task 2.5 - Now apply PCA to the brain and clinical data idependently and plot both:\n",
    "- The first two PCA components\n",
    "- The PCA latent space for the two first components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53105a75",
   "metadata": {
    "id": "53105a75"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e52580ec",
   "metadata": {
    "id": "e52580ec"
   },
   "source": [
    "#### Plotting PCA components (brain data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274b7206",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "274b7206",
    "outputId": "cea86274-cff8-420f-8eb2-a3fefa6ac5ab"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b02274bc",
   "metadata": {
    "id": "b02274bc"
   },
   "source": [
    "#### Plotting PCA latent components (brain data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F2ReMq3bxiGN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "F2ReMq3bxiGN",
    "outputId": "298a7392-ce68-4579-d507-f38e514c7840"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ef9c0e6",
   "metadata": {
    "id": "4ef9c0e6"
   },
   "source": [
    "#### Plotting PCA components (clinical data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce41404b",
   "metadata": {
    "id": "ce41404b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "271331f6",
   "metadata": {
    "id": "271331f6"
   },
   "source": [
    "#### Plotting PCA latent components (clinical data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d458e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "96d458e5",
    "outputId": "14569aaa-2a78-4882-f410-9d608e3c7850"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
